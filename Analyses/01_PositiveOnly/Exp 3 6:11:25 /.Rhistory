knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
source("helpers.R")
source("survey.R")
library(jsonlite)
allData <- read.csv("sociopolitical_frequency_pilot_v3-trials.csv")
allData <- read.csv("sociopolitical_frequency_v3_pilot-trials.csv")
testData <- extract_demographics(allData, "workerid", "response")
prolificIDs <- read.csv("sociopolitical_frequency_v3_pilot-workerids.csv")
prolificData <- read.csv("ProlificData.csv") %>%
mutate(prolific_participant_id = paste(Participant.id)) %>%
select(c("prolific_participant_id","U.s..political.affiliation","Age","Sex"))
testData <- testData %>%
left_join(prolificIDs, by=c("workerid"))
fullData <- testData %>%
left_join(prolificData, by=c("prolific_participant_id")) %>%
mutate(ProlificPolitical = paste(U.s..political.affiliation))
# Create political alignment function - this is not working because extract_demographics isn't
# determine_alignment <- function(participant_condition, wing_bias) {
#   if (is.na(participant_condition) || is.na(wing_bias) ||
#       participant_condition == "" || wing_bias == "") {
#     return(NA)
#   }
#
#   # Convert to lowercase for consistent matching
#   participant_condition <- tolower(participant_condition)
#   wing_bias <- tolower(wing_bias)
#
#   if (participant_condition == "progressive") {
#     return(ifelse(wing_bias == "left", "aligned",
#                   ifelse(wing_bias == "right", "disaligned", NA)))
#   } else if (participant_condition == "conservative") {
#     return(ifelse(wing_bias == "right", "aligned",
#                   ifelse(wing_bias == "left", "disaligned", NA)))
#   } else if (participant_condition %in% c("independent","moderate")) {
#     return("Useless")
#   }
#   return(NA)
# }
# First, create a reference dataset with political context information
political_context <- allData %>%
filter(!is.na(wingBias) & wingBias != "") %>%
select(workerid, criticalTerm, wingBias, tokenCount)
# Create lookup tables for token count and alignment by critical term and worker
token_lookup <- political_context %>%
select(workerid, criticalTerm, tokenCount) %>%
filter(criticalTerm %in% c("crowdcloaking","herdblurring","Thumaze","Wenlure","Churako","Domari","tessamorph","interforme")) %>%
distinct()
lexicalOnly <- allData %>%
filter(category == "LexicalDecision") %>%
mutate(criticalTerm = paste(stimulus)) %>%
# filter(criticality == "critical") %>%
# filter(itemPair %in% c("privacy","tattoos","martialArts","drugs")) %>%
select(c(-tokenCount))
allLexi <- lexicalOnly %>%
left_join(token_lookup %>%
select(workerid, criticalTerm, tokenCount) %>%
distinct(),
by = c("workerid", "criticalTerm")) %>%
mutate(binaryResponse = case_when(
statusCheck == "correct" ~ 1,
TRUE ~ 0
))
allLexi %>%
filter(wingBias != "NA") %>%
mutate(logRt = rt) %>%
mutate(alignment = case_when(
ProlificPolitical == "Democrat" & wingBias == "left" ~ "Aligned",
ProlificPolitical == "Republican" & wingBias == "right" ~ "Aligned",
TRUE ~ "Disaligned"
)) %>%
group_by(alignment,tokenCount) %>%
summarize(meanRt = mean(logRt),
CI.Low = ci.low(logRt),
CI.High = ci.high(logRt)) %>%
mutate(YMin = meanRt -CI.Low,
YMax = meanRt + CI.High) %>%
ggplot(aes(x=as.factor(tokenCount), y=meanRt, fill=alignment)) +
geom_bar(stat='identity', position=position_dodge()) +
geom_errorbar(aes(ymin = YMin, ymax = YMax, width=0.25), position = position_dodge(width=0.9) ) +
labs(x="Term Exposure", y="Log Response Time", fill="Term Bias") +
scale_x_discrete(labels=c("3" = "Low", "8" = "High")) +
theme_bw() +
scale_fill_brewer(palette="Accent")
# First, create a reference dataset with political context information
political_context <- fullData %>%
filter(!is.na(wingBias) & wingBias != "") %>%
select(workerid, criticalTerm, wingBias, tokenCount)
# Create lookup tables for token count and alignment by critical term and worker
token_lookup <- political_context %>%
select(workerid, criticalTerm, tokenCount) %>%
filter(criticalTerm %in% c("crowdcloaking","herdblurring","Thumaze","Wenlure","Churako","Domari","tessamorph","interforme")) %>%
distinct()
lexicalOnly <- fullData %>%
filter(category == "LexicalDecision") %>%
mutate(criticalTerm = paste(stimulus)) %>%
# filter(criticality == "critical") %>%
# filter(itemPair %in% c("privacy","tattoos","martialArts","drugs")) %>%
select(c(-tokenCount))
allLexi <- lexicalOnly %>%
left_join(token_lookup %>%
select(workerid, criticalTerm, tokenCount) %>%
distinct(),
by = c("workerid", "criticalTerm")) %>%
mutate(binaryResponse = case_when(
statusCheck == "correct" ~ 1,
TRUE ~ 0
))
allLexi %>%
filter(wingBias != "NA") %>%
mutate(logRt = rt) %>%
mutate(alignment = case_when(
ProlificPolitical == "Democrat" & wingBias == "left" ~ "Aligned",
ProlificPolitical == "Republican" & wingBias == "right" ~ "Aligned",
TRUE ~ "Disaligned"
)) %>%
group_by(alignment,tokenCount) %>%
summarize(meanRt = mean(logRt),
CI.Low = ci.low(logRt),
CI.High = ci.high(logRt)) %>%
mutate(YMin = meanRt -CI.Low,
YMax = meanRt + CI.High) %>%
ggplot(aes(x=as.factor(tokenCount), y=meanRt, fill=alignment)) +
geom_bar(stat='identity', position=position_dodge()) +
geom_errorbar(aes(ymin = YMin, ymax = YMax, width=0.25), position = position_dodge(width=0.9) ) +
labs(x="Term Exposure", y="Log Response Time", fill="Term Bias") +
scale_x_discrete(labels=c("3" = "Low", "8" = "High")) +
theme_bw() +
scale_fill_brewer(palette="Accent")
allLexi %>%
filter(wingBias != "NA") %>%
mutate(logRt = rt) %>%
mutate(alignment = case_when(
ProlificPolitical == "Democrat" & wingBias == "left" ~ "Aligned",
ProlificPolitical == "Republican" & wingBias == "right" ~ "Aligned",
TRUE ~ "Disaligned"
))
allData <- read.csv("sociopolitical_frequency_v3_pilot-trials.csv")
testData <- extract_demographics(allData, "workerid", "response")
prolificIDs <- read.csv("sociopolitical_frequency_v3_pilot-workerids.csv")
prolificData <- read.csv("ProlificData.csv") %>%
mutate(prolific_participant_id = paste(Participant.id)) %>%
select(c("prolific_participant_id","U.s..political.affiliation","Age","Sex"))
testData <- testData %>%
left_join(prolificIDs, by=c("workerid"))
fullData <- testData %>%
left_join(prolificData, by=c("prolific_participant_id")) %>%
mutate(ProlificPolitical = paste(U.s..political.affiliation))
View(fullData)
# First, create a reference dataset with political context information
political_context <- fullData %>%
filter(!is.na(wingBias) & wingBias != "") %>%
select(workerid, criticalTerm, wingBias, tokenCount)
View(political_context)
# Create lookup tables for token count and alignment by critical term and worker
token_lookup <- political_context %>%
select(workerid, criticalTerm, tokenCount) %>%
filter(criticalTerm %in% c("crowdcloaking","herdblurring","Thumaze","Wenlure","Churako","Domari","tessamorph","interforme")) %>%
distinct()
View(token_lookup)
# Create lookup tables for token count and alignment by critical term and worker
token_lookup <- political_context %>%
select(workerid, criticalTerm, tokenCount,wingBias) %>%
filter(criticalTerm %in% c("crowdcloaking","herdblurring","Thumaze","Wenlure","Churako","Domari","tessamorph","interforme")) %>%
distinct()
lexicalOnly <- fullData %>%
filter(category == "LexicalDecision") %>%
mutate(criticalTerm = paste(stimulus)) %>%
# filter(criticality == "critical") %>%
# filter(itemPair %in% c("privacy","tattoos","martialArts","drugs")) %>%
select(c(-tokenCount))
allLexi <- lexicalOnly %>%
left_join(token_lookup %>%
select(workerid, criticalTerm, tokenCount) %>%
distinct(),
by = c("workerid", "criticalTerm")) %>%
mutate(binaryResponse = case_when(
statusCheck == "correct" ~ 1,
TRUE ~ 0
))
allLexi %>%
filter(wingBias != "NA") %>%
mutate(logRt = rt) %>%
mutate(alignment = case_when(
ProlificPolitical == "Democrat" & wingBias == "left" ~ "Aligned",
ProlificPolitical == "Republican" & wingBias == "right" ~ "Aligned",
TRUE ~ "Disaligned"
)) %>%
group_by(alignment,tokenCount) %>%
summarize(meanRt = mean(logRt),
CI.Low = ci.low(logRt),
CI.High = ci.high(logRt)) %>%
mutate(YMin = meanRt -CI.Low,
YMax = meanRt + CI.High) %>%
ggplot(aes(x=as.factor(tokenCount), y=meanRt, fill=alignment)) +
geom_bar(stat='identity', position=position_dodge()) +
geom_errorbar(aes(ymin = YMin, ymax = YMax, width=0.25), position = position_dodge(width=0.9) ) +
labs(x="Term Exposure", y="Log Response Time", fill="Term Bias") +
scale_x_discrete(labels=c("3" = "Low", "8" = "High")) +
theme_bw() +
scale_fill_brewer(palette="Accent")
View(token_lookup)
View(allLexi)
allLexi <- lexicalOnly %>%
left_join(token_lookup %>%
select(workerid, criticalTerm, tokenCount, wingBias) %>%
distinct(),
by = c("workerid", "criticalTerm")) %>%
mutate(binaryResponse = case_when(
statusCheck == "correct" ~ 1,
TRUE ~ 0
))
allLexi %>%
filter(wingBias.y != "NA") %>%
mutate(logRt = rt) %>%
mutate(alignment = case_when(
ProlificPolitical == "Democrat" & wingBias.y == "left" ~ "Aligned",
ProlificPolitical == "Republican" & wingBias.y == "right" ~ "Aligned",
TRUE ~ "Disaligned"
)) %>%
group_by(alignment,tokenCount) %>%
summarize(meanRt = mean(logRt),
CI.Low = ci.low(logRt),
CI.High = ci.high(logRt)) %>%
mutate(YMin = meanRt -CI.Low,
YMax = meanRt + CI.High) %>%
ggplot(aes(x=as.factor(tokenCount), y=meanRt, fill=alignment)) +
geom_bar(stat='identity', position=position_dodge()) +
geom_errorbar(aes(ymin = YMin, ymax = YMax, width=0.25), position = position_dodge(width=0.9) ) +
labs(x="Term Exposure", y="Log Response Time", fill="Term Bias") +
scale_x_discrete(labels=c("3" = "Low", "8" = "High")) +
theme_bw() +
scale_fill_brewer(palette="Accent")
