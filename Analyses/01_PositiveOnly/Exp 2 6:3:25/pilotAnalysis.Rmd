---
title: "Sociopolitical Frequency Effects"
author: "Brandon Papineau"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
source("helpers.R")
source("survey.R")
library(jsonlite)
```

```{r}
allData <- read.csv("sociopolitical_frequency_tradeoff_v2-merged.csv")
```

```{r}
allData <- extract_demographics(allData, "workerid", "response")
```


```{r}
# Create political alignment function
determine_alignment <- function(participant_condition, wing_bias) {
  if (is.na(participant_condition) || is.na(wing_bias) || 
      participant_condition == "" || wing_bias == "") {
    return(NA)
  }
  
  # Convert to lowercase for consistent matching
  participant_condition <- tolower(participant_condition)
  wing_bias <- tolower(wing_bias)
  
  if (participant_condition == "progressive") {
    return(ifelse(wing_bias == "left", "aligned", 
                  ifelse(wing_bias == "right", "disaligned", NA)))
  } else if (participant_condition == "conservative") {
    return(ifelse(wing_bias == "right", "aligned", 
                  ifelse(wing_bias == "left", "disaligned", NA)))
  } else if (participant_condition %in% c("independent","moderate")) {
    return("Useless")
  }
  return(NA)
}

# First, create a reference dataset with political context information
political_context <- allData %>%
  filter(!is.na(wingBias) & wingBias != "") %>%
  select(workerid, criticalTerm, wingBias, tokenCount, political) %>%
  mutate(
    political_alignment = mapply(determine_alignment, 
                               political, 
                               wingBias) 
  )

# Create lookup tables for token count and alignment by critical term and worker
token_lookup <- political_context %>%
  select(workerid, criticalTerm, tokenCount) %>%
  filter(criticalTerm %in% c("crowdcloaking","herdblurring","Thumaze","Wenlure","Churako","Domari","tessamorph","interforme")) %>% 
  distinct() 

alignment_lookup <- political_context %>%
  select(workerid, criticalTerm, political_alignment) %>%
  # filter(criticalTerm %in% c("crowdcloaking","herdblurring","Thumaze","Wenlure","Churako","Domari","tessamorph","interforme")) %>% 
  distinct() 

lexicalOnly <- allData %>% 
  filter(category == "LexicalDecision") %>% 
  mutate(criticalTerm = paste(stimulus)) %>% 
  filter(criticality == "critical") %>% 
  filter(itemPair %in% c("privacy","tattoos","martialArts","drugs")) %>% 
  select(c(-tokenCount))

allLexi <- lexicalOnly %>%
  left_join(metadata %>% 
            select(workerid, criticalTerm, tokenCount, political_alignment) %>%
            distinct(), 
            by = c("workerid", "criticalTerm")) %>%
  mutate(binaryResponse = case_when(  
    statusCheck == "correct" ~ 1,
    TRUE ~ 0
  ))

# metadata <- left_join(alignment_lookup,token_lookup)
# 
# allLexi <- left_join(lexicalOnly,metadata, by="criticalTerm") 
# 
# allLexi <- allLexi %>% 
#   mutate(binaryRespose = case_when(
#     statusCheck == "correct" ~ 1,
#     TRUE ~ 0
#   ))
```

```{r}
allData %>% 
  filter(category == "LexicalDecision") %>% 
  mutate(binaryResponse = case_when(
    statusCheck == "correct" ~ 1,
    TRUE ~ 0
  )) %>% 
  group_by(status) %>% 
  summarize(meanAcc = mean(binaryResponse),
            CI.Low = ci.low(binaryResponse),
            CI.High = ci.high(binaryResponse)) %>% 
  mutate(
    YMin = meanAcc - CI.Low,
    YMax = meanAcc + CI.High
  ) %>%
  ggplot(aes(x=as.factor(status), y= meanAcc)) +
  geom_bar(stat='identity') + 
  geom_errorbar(aes(ymin = YMin, ymax = YMax, width=0.25), position = position_dodge(width=0.9) ) + 
  theme_bw()
```

```{r}
allLexi %>% 
  group_by(tokenCount, workerid) %>% 
  summarize(meanAcc = mean(binaryResponse),
            CI.Low = ci.low(binaryResponse),
            CI.High = ci.high(binaryResponse)) %>% 
  mutate(
    YMin = meanAcc - CI.Low,
    YMax = meanAcc + CI.High
  ) %>%
  ggplot(aes(x=as.factor(tokenCount), y= meanAcc)) +
  geom_bar(stat='identity') + 
  geom_errorbar(aes(ymin = YMin, ymax = YMax, width=0.25), position = position_dodge(width=0.9) ) + 
  facet_wrap(~workerid) +
  theme_bw()
```


```{r}
allLexi %>% 
  group_by(tokenCount,workerid.x) %>% 
  summarize(meanRt = mean(rt),
            CI.Low = ci.low(rt),
            CI.High = ci.high(rt)) %>% 
  mutate(
    YMin = meanRt - CI.Low,
    YMax = meanRt + CI.High
  ) %>%
  ggplot(aes(x=as.factor(tokenCount), y= meanRt)) +
  geom_bar(stat='identity') + 
  geom_errorbar(aes(ymin = YMin, ymax = YMax, width=0.25), position = position_dodge(width=0.9) ) + 
  facet_wrap(~workerid.x)
  theme_bw()
```
```{r}
allLexi %>% 
  group_by(workerid.x, tokenCount) %>% 
  ggplot(aes(x = rt, fill = as.factor(tokenCount), group = as.character(tokenCount))) + 
  geom_density(aes(alpha = 0.4)) + 
  geom_rug(aes(color = as.factor(tokenCount)))
  
```


```{r}
df_cleaned %>% 
  filter(statusCheck == "correct") %>% 
  filter(political %in% c('Progressive','Conservative')) %>% 
  group_by(political_alignment,tokenCount,political) %>% 
  summarize(meanRT = mean(rt),
            CI.Low = ci.low(rt),
            CI.High = ci.high(rt)) %>% 
  mutate(
    YMin = meanRT - CI.Low,
    YMax = meanRT + CI.High
  ) %>%
  ggplot(aes(x = as.factor(political_alignment), y = meanRT, fill=political)) + 
  geom_bar(stat="identity", position = position_dodge(width = 0.9)) + 
  geom_errorbar(aes(ymin = YMin, ymax = YMax, width=0.25), position = position_dodge(width=0.9) ) + 
  facet_wrap(~tokenCount)
```


```{r}
allReading <- allData %>% 
  filter(category == "trial") %>% 
  group_by(wingBias, political) %>% 
  summarize(meanRt = mean(rt))
```

```{r}
target_words <- c("wenlure", "thumaze", "domari", "churako", "herdblurring", 
                  "crowdcloaking", "interforme", "tessamorph")

# Filter using case-insensitive regex
allProduction %>%
  filter(category == "tweet_production") %>% 
  group_by(isExposed) %>% 
  summarize(count = n())
```



```{r}
allProduction <- allData %>% 
  filter(category == "tweet_production") %>% 
  filter(response %in% c("Wenlure","wenlure","Thumaze","thumaze","Domari","domari","Churako","churako","herdblurring","Herdblurring","Crowdcloaking","crowdcloaking","interforme","Interforme","tessamorph","Tessamorph"))
```

```{r}
allData %>% 
  select(c("workerid","correct","political")) %>% 
  unique() %>% 
  group_by(correct,political) %>% 
  summarize(n = n())
```

