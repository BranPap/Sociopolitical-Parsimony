---
title: "Sociopolitical Frequency Effects"
author: "Brandon Papineau"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
source("helpers.R")
```

```{r}
leftWingData <- read_csv("sociopoliticalfrequencypilotleft-merged.csv")

rightWingData <- read_csv("sociopoliticalfrequencypilotright-merged.csv")

allData <- rbind(leftWingData,rightWingData)
```


```{r}
allData %>% 
  filter(category == "LexicalDecision") %>% 
  filter(status == "old") %>% 
  filter(criticality == "critical") %>% 
  group_by(itemPair,stimulus) %>% 
  summarize(meanRT = mean(rt)) %>% 
  ggplot(aes(x=itemPair,fill=stimulus,y=meanRT)) + 
  geom_bar(stat='identity', position = position_dodge(width=0.9))
```

```{r}
leftWingData %>% 
  mutate(alignment = case_when(wingBias == "left" ~ "aligned",
                               is.na(wingBias) ~ "none",
                               TRUE ~ "disaligned")) %>% 
  filter(category == "LexicalDecision") %>% 
  filter(criticality == "critical") %>% 
  group_by(alignment) %>% 
  summarize(meanRt = mean(rt))
```




# Reading Task


# Lexical Decision


# Captioning

```{r}
allData %>% 
  filter(trial_type == "image-caption") %>% 
  group_by(caption_prefix, response) %>% 
  summarize(count = n()) %>% 
  ggplot(aes(x=caption_prefix, y=count, fill=response)) + 
  geom_bar(stat='identity') +
  coord_flip() + 
  theme(legend.position = "none")
```


```{r}
# Create political alignment function
determine_alignment <- function(participant_condition, wing_bias) {
  if (is.na(participant_condition) || is.na(wing_bias) || 
      participant_condition == "" || wing_bias == "") {
    return(NA)
  }
  
  # Convert to lowercase for consistent matching
  participant_condition <- tolower(participant_condition)
  wing_bias <- tolower(wing_bias)
  
  if (participant_condition == "democrats") {
    return(ifelse(wing_bias == "left", "aligned", 
                  ifelse(wing_bias == "right", "disaligned", NA)))
  } else if (participant_condition == "republicans") {
    return(ifelse(wing_bias == "right", "aligned", 
                  ifelse(wing_bias == "left", "disaligned", NA)))
  }
  return(NA)
}

# First, create a reference dataset with political context information
political_context <- allData %>%
  filter(!is.na(wingBias) & wingBias != "") %>%
  select(workerid, criticalTerm, wingBias, tokenCount, proliferate.condition) %>%
  mutate(
    political_alignment = mapply(determine_alignment, 
                               proliferate.condition, 
                               wingBias) 
  )

# Create lookup tables for token count and alignment by critical term and worker
token_lookup <- political_context %>%
  select(workerid, criticalTerm, tokenCount) %>%
  filter(criticalTerm %in% c("crowdcloaking","herdblurring","Thumaze","Wenlure","Churako","Domari","tessamorph","interforme")) %>% 
  distinct() 

alignment_lookup <- political_context %>%
  select(workerid, criticalTerm, political_alignment) %>%
  filter(criticalTerm %in% c("crowdcloaking","herdblurring","Thumaze","Wenlure","Churako","Domari","tessamorph","interforme")) %>% 
  distinct() 

lexicalOnly <- allData %>% 
  filter(category == "LexicalDecision") %>% 
  mutate(criticalTerm = paste(stimulus)) %>% 
  filter(criticality == "critical") %>% 
  filter(itemPair %in% c("datingProfiles","tattoo","martialArts","medicine")) %>% 
  select(c(-tokenCount))

metadata <- left_join(alignment_lookup,token_lookup)

allLexi <- left_join(lexicalOnly,metadata, by="criticalTerm") %>% 
  filter(workerid.x == workerid.y)

allLexi <- allLexi %>% 
  mutate(binaryRespose = case_when(
    statusCheck == "correct" ~ 1,
    TRUE ~ 0
  ))
```

```{r}
allLexi %>% 
  filter(binaryRespose == 1) %>% 
  mutate(tokenCount = as.factor(tokenCount)) %>% 
  group_by(political_alignment,tokenCount) %>% 
  summarize(meanRT = mean(rt),
            CI.Low = ci.low(rt),
            CI.High = ci.high(rt)) %>% 
  mutate(
    YMin = meanRT - CI.Low,
    YMax = meanRT + CI.High
  ) %>% 
  ggplot(aes(x=political_alignment, y = meanRT, fill= tokenCount)) + 
  geom_bar(stat='identity', position = position_dodge(width=0.9)) + 
  geom_errorbar(aes(ymin = YMin, ymax = YMax, width=0.25), position = position_dodge(width=0.9) ) + 
  theme_bw()
```


```{r}
allLexi %>% 
  mutate(tokenCount = as.factor(tokenCount)) %>% 
  group_by(tokenCount) %>% 
  summarize(meanCorrect = mean(binaryRespose),
            CI.Low = ci.low(binaryRespose),
            CI.High = ci.high(binaryRespose)) %>% 
  mutate(
    YMin = meanCorrect - CI.Low,
    YMax = meanCorrect + CI.High
  ) %>% 
  ggplot(aes(x=tokenCount, y = meanCorrect, fill= tokenCount)) + 
  geom_bar(stat='identity', position = position_dodge(width=0.9)) + 
  geom_errorbar(aes(ymin = YMin, ymax = YMax, width=0.25), position = position_dodge(width=0.9) ) + 
  theme_bw()
```


```{r}
allCaptions <- allData %>% 
  filter(trial_type == "image-caption")

allCaptions %>% 
  select(c("caption_prefix","response")) %>%
  group_by(caption_prefix,response) %>% 
  summarize(count = n()) %>% 
  ggplot(aes(x=caption_prefix, y=count, fill=response)) + 
  geom_bar(stat='identity', position='dodge') + 
  coord_flip()
```



```{r}
allCaptions %>%
  group_by(caption_prefix, response) %>%
  summarise(count = n(), .groups = 'drop')
```


# Self-Paced Reading

```{r}
sprData <- allData %>% 
  filter(category == "selfPacedReading")
```

```{r}
sprData %>%
  oiajfa
```



# Grammaticality 

```{r}
grammaticalityData <- allData %>% 
  filter(category == "PositiveAnymore")
```

